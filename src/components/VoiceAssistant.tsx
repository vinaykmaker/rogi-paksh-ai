import React, { useState, useRef, useEffect, useCallback } from 'react';
import { Mic, MicOff, Volume2, VolumeX, Loader2, Bot, MessageSquare } from 'lucide-react';
import { Button } from '@/components/ui/button';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { supabase } from '@/integrations/supabase/client';
import { useToast } from '@/hooks/use-toast';
import { useSpeechSynthesis, getLocalizedText } from '@/hooks/useSpeechSynthesis';

interface VoiceAssistantProps {
  currentLanguage: string;
  translations: any;
}

const LANG_CODES: Record<string, string> = {
  en: 'en-IN',
  hi: 'hi-IN',
  kn: 'kn-IN'
};

const VoiceAssistant: React.FC<VoiceAssistantProps> = ({ currentLanguage, translations }) => {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [response, setResponse] = useState<{ en: string; hi: string; kn: string } | null>(null);
  const [isProcessing, setIsProcessing] = useState(false);
  const recognitionRef = useRef<any>(null);
  const { toast } = useToast();
  const { speak, stop, isSpeaking, isSupported: ttsSupported } = useSpeechSynthesis({ 
    language: currentLanguage,
    rate: 0.85 
  });

  // Initialize speech recognition
  useEffect(() => {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
      recognitionRef.current = new SpeechRecognition();
      recognitionRef.current.continuous = true;
      recognitionRef.current.interimResults = true;

      recognitionRef.current.onresult = (event: any) => {
        let finalTranscript = '';
        for (let i = event.resultIndex; i < event.results.length; i++) {
          if (event.results[i].isFinal) {
            finalTranscript += event.results[i][0].transcript;
          }
        }
        if (finalTranscript) setTranscript(finalTranscript);
      };

      recognitionRef.current.onerror = (event: any) => {
        console.error('Speech recognition error:', event.error);
        setIsListening(false);
        if (event.error === 'not-allowed') {
          toast({
            title: currentLanguage === 'hi' ? '‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§´‡§º‡•ã‡§® ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§Ö‡§∏‡•ç‡§µ‡•Ä‡§ï‡•É‡§§' : currentLanguage === 'kn' ? '‡≤Æ‡≥à‡≤ï‡≥ç‡≤∞‡≥ã‡≤´‡≥ã‡≤®‡≥ç ‡≤Ö‡≤®‡≥Å‡≤Æ‡≤§‡≤ø ‡≤®‡≤ø‡≤∞‡≤æ‡≤ï‡≤∞‡≤ø‡≤∏‡≤≤‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü' : 'Microphone Access Denied',
            description: currentLanguage === 'hi' ? '‡§ï‡•É‡§™‡§Ø‡§æ ‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§´‡§º‡•ã‡§® ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§Ç' : currentLanguage === 'kn' ? '‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤Æ‡≥à‡≤ï‡≥ç‡≤∞‡≥ã‡≤´‡≥ã‡≤®‡≥ç ‡≤™‡≥ç‡≤∞‡≤µ‡≥á‡≤∂‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤Ö‡≤®‡≥Å‡≤Æ‡≤§‡≤ø‡≤∏‡≤ø' : 'Please allow microphone access',
            variant: "destructive"
          });
        }
      };

      recognitionRef.current.onend = () => setIsListening(false);
    }

    return () => {
      if (recognitionRef.current) recognitionRef.current.stop();
    };
  }, [toast, currentLanguage]);

  const toggleListening = useCallback(() => {
    if (!recognitionRef.current) {
      toast({
        title: currentLanguage === 'hi' ? '‡§∏‡§Æ‡§∞‡•ç‡§•‡§ø‡§§ ‡§®‡§π‡•Ä‡§Ç' : currentLanguage === 'kn' ? '‡≤¨‡≥Ü‡≤Ç‡≤¨‡≤≤‡≤µ‡≤ø‡≤≤‡≥ç‡≤≤' : 'Not Supported',
        description: currentLanguage === 'hi' ? '‡§á‡§∏ ‡§¨‡•ç‡§∞‡§æ‡§â‡§ú‡§º‡§∞ ‡§Æ‡•á‡§Ç ‡§µ‡•â‡§Ø‡§∏ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§ø‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à' : currentLanguage === 'kn' ? '‡≤à ‡≤¨‡≥ç‡≤∞‡≥å‡≤∏‡≤∞‡≥ç‚Äå‡≤®‡≤≤‡≥ç‡≤≤‡≤ø ‡≤ß‡≥ç‡≤µ‡≤®‡≤ø ‡≤¨‡≥Ü‡≤Ç‡≤¨‡≤≤‡≤µ‡≤ø‡≤≤‡≥ç‡≤≤' : 'Voice not supported in this browser',
        variant: "destructive"
      });
      return;
    }

    if (isListening) {
      recognitionRef.current.stop();
      setIsListening(false);
      if (transcript) processQuestion(transcript);
    } else {
      setTranscript('');
      setResponse(null);
      recognitionRef.current.lang = LANG_CODES[currentLanguage] || 'en-IN';
      try {
        recognitionRef.current.start();
        setIsListening(true);
      } catch (error) {
        console.error('Failed to start recognition:', error);
      }
    }
  }, [isListening, transcript, currentLanguage, toast]);

  const processQuestion = async (question: string) => {
    setIsProcessing(true);
    
    try {
      const { data, error } = await supabase.functions.invoke('agribot-chat', {
        body: { question }
      });

      if (error) throw error;

      if (data.en && data.hi && data.kn) {
        setResponse(data);
        // Auto-speak response
        const textToSpeak = getLocalizedText(data, currentLanguage);
        speak(textToSpeak);
      } else if (data.error) {
        toast({ title: "Error", description: data.error, variant: "destructive" });
      }
    } catch (error) {
      console.error('Failed to process question:', error);
      toast({
        title: currentLanguage === 'hi' ? '‡§§‡•ç‡§∞‡•Å‡§ü‡§ø' : currentLanguage === 'kn' ? '‡≤¶‡≥ã‡≤∑' : 'Error',
        description: currentLanguage === 'hi' ? '‡§ú‡§µ‡§æ‡§¨ ‡§™‡§æ‡§®‡•á ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§´‡§≤‡•§ ‡§™‡•Å‡§®‡§É ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡•á‡§Ç‡•§' : currentLanguage === 'kn' ? '‡≤â‡≤§‡≥ç‡≤§‡≤∞ ‡≤™‡≤°‡≥Ü‡≤Ø‡≤≤‡≥Å ‡≤µ‡≤ø‡≤´‡≤≤. ‡≤Æ‡≤§‡≥ç‡≤§‡≥Ü ‡≤™‡≥ç‡≤∞‡≤Ø‡≤§‡≥ç‡≤®‡≤ø‡≤∏‡≤ø.' : 'Failed to get response. Please try again.',
        variant: "destructive"
      });
    } finally {
      setIsProcessing(false);
    }
  };

  const handleSpeak = () => {
    if (!response) return;
    if (isSpeaking) {
      stop();
    } else {
      speak(getLocalizedText(response, currentLanguage));
    }
  };

  const exampleQueries = [
    { en: "Why are my tomato leaves turning yellow?", hi: "‡§Æ‡•á‡§∞‡•á ‡§ü‡§Æ‡§æ‡§ü‡§∞ ‡§ï‡•Ä ‡§™‡§§‡•ç‡§§‡§ø‡§Ø‡§æ‡§Ç ‡§™‡•Ä‡§≤‡•Ä ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‡§Ç?", kn: "‡≤®‡≤®‡≥ç‡≤® ‡≤ü‡≥ä‡≤Æ‡≥Ü‡≤ü‡≥ä ‡≤é‡≤≤‡≥Ü‡≤ó‡≤≥‡≥Å ‡≤è‡≤ï‡≥Ü ‡≤π‡≤≥‡≤¶‡≤ø ‡≤Ü‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤µ‡≥Ü?" },
    { en: "How to control aphids on my crops?", hi: "‡§Ö‡§™‡§®‡•Ä ‡§´‡§∏‡§≤‡•ã‡§Ç ‡§™‡§∞ ‡§è‡§´‡§ø‡§°‡•ç‡§∏ ‡§ï‡•à‡§∏‡•á ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç?", kn: "‡≤®‡≤®‡≥ç‡≤® ‡≤¨‡≥Ü‡≤≥‡≥Ü‡≤ó‡≤≥‡≤≤‡≥ç‡≤≤‡≤ø ‡≤π‡≥á‡≤®‡≥Å‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≥á‡≤ó‡≥Ü ‡≤®‡≤ø‡≤Ø‡≤Ç‡≤§‡≥ç‡≤∞‡≤ø‡≤∏‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å?" },
    { en: "Best time to apply fertilizer for rice?", hi: "‡§ö‡§æ‡§µ‡§≤ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ñ‡§æ‡§¶ ‡§°‡§æ‡§≤‡§®‡•á ‡§ï‡§æ ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§∏‡§Æ‡§Ø?", kn: "‡≤≠‡≤§‡≥ç‡≤§‡≤ï‡≥ç‡≤ï‡≥Ü ‡≤ó‡≥ä‡≤¨‡≥ç‡≤¨‡≤∞ ‡≤π‡≤æ‡≤ï‡≤≤‡≥Å ‡≤â‡≤§‡≥ç‡≤§‡≤Æ ‡≤∏‡≤Æ‡≤Ø?" }
  ];

  const labels = {
    en: { title: 'üéôÔ∏è AI Voice Assistant', subtitle: 'Speak and hear answers in your language', speak: 'Speak', stop: 'Stop', listening: 'üé§ Listening... Speak now!', pressToSpeak: 'Press the button and ask your question', youSaid: 'You said:', thinking: 'Thinking...', listen: 'Listen', tryAsking: 'üí° Try asking:' },
    hi: { title: 'üéôÔ∏è AI ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡§π‡§æ‡§Ø‡§ï', subtitle: '‡§Ö‡§™‡§®‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§¨‡•ã‡§≤‡•á‡§Ç ‡§î‡§∞ ‡§ú‡§µ‡§æ‡§¨ ‡§∏‡•Å‡§®‡•á‡§Ç', speak: '‡§¨‡•ã‡§≤‡•á‡§Ç', stop: '‡§∞‡•ã‡§ï‡•á‡§Ç', listening: 'üé§ ‡§∏‡•Å‡§® ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç... ‡§¨‡•ã‡§≤‡•á‡§Ç!', pressToSpeak: '‡§¨‡§ü‡§® ‡§¶‡§¨‡§æ‡§ï‡§∞ ‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§¨‡•ã‡§≤‡•á‡§Ç', youSaid: '‡§Ü‡§™‡§®‡•á ‡§ï‡§π‡§æ:', thinking: '‡§∏‡•ã‡§ö ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç...', listen: '‡§∏‡•Å‡§®‡•á‡§Ç', tryAsking: 'üí° ‡§ê‡§∏‡•á ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡•á‡§Ç:' },
    kn: { title: 'üéôÔ∏è AI ‡≤ß‡≥ç‡≤µ‡≤®‡≤ø ‡≤∏‡≤π‡≤æ‡≤Ø‡≤ï', subtitle: '‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤≠‡≤æ‡≤∑‡≥Ü‡≤Ø‡≤≤‡≥ç‡≤≤‡≤ø ‡≤Æ‡≤æ‡≤§‡≤®‡≤æ‡≤°‡≤ø ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤â‡≤§‡≥ç‡≤§‡≤∞ ‡≤ï‡≥á‡≤≥‡≤ø', speak: '‡≤Æ‡≤æ‡≤§‡≤®‡≤æ‡≤°‡≤ø', stop: '‡≤®‡≤ø‡≤≤‡≥ç‡≤≤‡≤ø‡≤∏‡≤ø', listening: 'üé§ ‡≤ï‡≥á‡≤≥‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥Ü... ‡≤Æ‡≤æ‡≤§‡≤®‡≤æ‡≤°‡≤ø!', pressToSpeak: '‡≤¨‡≤ü‡≤®‡≥ç ‡≤í‡≤§‡≥ç‡≤§‡≤ø ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü ‡≤π‡≥á‡≤≥‡≤ø', youSaid: '‡≤®‡≥Ä‡≤µ‡≥Å ‡≤π‡≥á‡≤≥‡≤ø‡≤¶‡≥ç‡≤¶‡≥Å:', thinking: '‡≤Ø‡≥ã‡≤ö‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥Ü...', listen: '‡≤ï‡≥á‡≤≥‡≤ø', tryAsking: 'üí° ‡≤à ‡≤∞‡≥Ä‡≤§‡≤ø ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤ï‡≥á‡≤≥‡≤ø:' }
  };
  const t = labels[currentLanguage as keyof typeof labels] || labels.en;

  return (
    <Card className="w-full shadow-strong border-2 border-accent/30">
      <CardHeader className="bg-gradient-to-r from-accent to-accent-light text-accent-foreground rounded-t-lg">
        <CardTitle className="flex items-center gap-3 text-xl md:text-2xl">
          <Mic className="h-7 w-7" />
          {t.title}
        </CardTitle>
        <p className="text-accent-foreground/80 text-sm md:text-base">{t.subtitle}</p>
      </CardHeader>

      <CardContent className="p-4 md:p-6 space-y-6">
        {/* Voice Input Button */}
        <div className="flex flex-col items-center space-y-4">
          <Button
            onClick={toggleListening}
            disabled={isProcessing}
            size="lg"
            className={`w-32 h-32 rounded-full text-lg transition-all duration-300 ${
              isListening 
                ? 'bg-red-500 hover:bg-red-600 animate-pulse scale-110' 
                : 'bg-primary hover:bg-primary/90'
            }`}
          >
            {isListening ? (
              <div className="flex flex-col items-center">
                <MicOff className="h-12 w-12 mb-1" />
                <span className="text-xs">{t.stop}</span>
              </div>
            ) : (
              <div className="flex flex-col items-center">
                <Mic className="h-12 w-12 mb-1" />
                <span className="text-xs">{t.speak}</span>
              </div>
            )}
          </Button>

          <p className="text-center text-muted-foreground text-sm">
            {isListening ? (
              <span className="text-red-500 font-medium animate-pulse">{t.listening}</span>
            ) : (
              <span>{t.pressToSpeak}</span>
            )}
          </p>
        </div>

        {/* Transcript */}
        {transcript && (
          <div className="bg-muted p-4 rounded-lg">
            <p className="text-sm text-muted-foreground mb-1">{t.youSaid}</p>
            <p className="font-medium text-lg">{transcript}</p>
          </div>
        )}

        {/* Processing Indicator */}
        {isProcessing && (
          <div className="flex items-center justify-center gap-3 py-6">
            <Loader2 className="h-8 w-8 animate-spin text-primary" />
            <span className="text-lg">{t.thinking}</span>
          </div>
        )}

        {/* Response */}
        {response && !isProcessing && (
          <div className="bg-primary/10 p-4 rounded-xl border border-primary/20 animate-in fade-in slide-in-from-bottom-4">
            <div className="flex items-start gap-3 mb-3">
              <div className="w-10 h-10 rounded-full bg-primary flex items-center justify-center flex-shrink-0">
                <Bot className="h-6 w-6 text-white" />
              </div>
              <div className="flex-1">
                <div className="flex items-center justify-between mb-2">
                  <span className="font-semibold">
                    {currentLanguage === 'hi' ? '‡§è‡§ó‡•ç‡§∞‡•Ä‡§¨‡•â‡§ü' : currentLanguage === 'kn' ? '‡≤Ö‡≤ó‡≥ç‡≤∞‡≤ø‡≤¨‡≤æ‡≤ü‡≥ç' : 'AgriBot'}
                  </span>
                  <Button onClick={handleSpeak} variant="ghost" size="sm" className="gap-2">
                    {isSpeaking ? (
                      <><VolumeX className="h-5 w-5" />{t.stop}</>
                    ) : (
                      <><Volume2 className="h-5 w-5" />{t.listen}</>
                    )}
                  </Button>
                </div>
                <p className="text-foreground whitespace-pre-line leading-relaxed">
                  {getLocalizedText(response, currentLanguage)}
                </p>
              </div>
            </div>
          </div>
        )}

        {/* Example Queries */}
        {!response && !transcript && (
          <div className="space-y-3">
            <p className="text-sm text-muted-foreground font-medium">{t.tryAsking}</p>
            <div className="grid gap-2">
              {exampleQueries.map((query, index) => (
                <Button
                  key={index}
                  variant="outline"
                  className="justify-start text-left h-auto py-3 px-4"
                  onClick={() => {
                    const q = getLocalizedText(query, currentLanguage);
                    setTranscript(q);
                    processQuestion(q);
                  }}
                >
                  <MessageSquare className="h-4 w-4 mr-3 flex-shrink-0" />
                  <span className="text-sm">{getLocalizedText(query, currentLanguage)}</span>
                </Button>
              ))}
            </div>
          </div>
        )}
      </CardContent>
    </Card>
  );
};

export default VoiceAssistant;
